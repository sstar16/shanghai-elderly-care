import os
import time
import csv
import requests
import psycopg2
import subprocess

# ========== ä½ çš„é…ç½® ==========
API_KEY = "770ef757ce3d1aea282891bf2c03d221"

# ç¡®ä¿ä½¿ç”¨dataæ–‡ä»¶å¤¹ä¸­çš„cleanedæ–‡ä»¶
LOCAL_ELDER_CSV = r"D:\geodb\data\elderly_cleaned.csv"
LOCAL_HEALTH_CSV = r"D:\geodb\data\health_cleaned.csv"

CONTAINER_NAME = "geodb"

DB_HOST = "localhost"
DB_PORT = "5433"
DB_NAME = "elder"
DB_USER = "lzhd"
DB_PASSWORD = "1"
# ==============================
MAX_RETRIES = 5

# -------- æ‰“å°ç¾è§‚æ—¥å¿— --------
def info(msg):
    print(f"ğŸ‘‰ {msg}")

def success(msg):
    print(f"âœ” {msg}")

def error(msg):
    print(f"âŒ {msg}")


# -------- 1. å°† CSV å¤åˆ¶è¿›å®¹å™¨ --------
def copy_csv_to_container():
    info("å¼€å§‹å¤åˆ¶ CSV æ–‡ä»¶åˆ° Docker å®¹å™¨ä¸­...")
    
    # å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨äºdataæ–‡ä»¶å¤¹ä¸­
    if not os.path.exists(LOCAL_ELDER_CSV):
        error(f"é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ - {LOCAL_ELDER_CSV}")
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {LOCAL_ELDER_CSV}")
    
    if not os.path.exists(LOCAL_HEALTH_CSV):
        error(f"é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ - {LOCAL_HEALTH_CSV}")
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {LOCAL_HEALTH_CSV}")
    
    # å…ˆåœ¨å®¹å™¨ä¸­åˆ›å»ºdataç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    subprocess.run(["docker", "exec", CONTAINER_NAME, "mkdir", "-p", "/data"], check=True)
    
    # å¤åˆ¶æ–‡ä»¶åˆ°å®¹å™¨çš„dataç›®å½•
    subprocess.run(["docker", "cp", LOCAL_ELDER_CSV, f"{CONTAINER_NAME}:/data/elderly_cleaned.csv"], check=True)
    subprocess.run(["docker", "cp", LOCAL_HEALTH_CSV, f"{CONTAINER_NAME}:/data/health_cleaned.csv"], check=True)

    success("CSV æ–‡ä»¶å¤åˆ¶æˆåŠŸï¼")


# -------- 2. åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„ --------
def init_tables():
    info("åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„...")

    conn = psycopg2.connect(
        host=DB_HOST, port=DB_PORT, dbname=DB_NAME,
        user=DB_USER, password=DB_PASSWORD
    )
    cur = conn.cursor()

    sql = """
    DROP TABLE IF EXISTS elderly_service;
    CREATE TABLE elderly_service (
        id SERIAL PRIMARY KEY,
        district TEXT,
        street TEXT,
        name TEXT NOT NULL,
        beds INTEGER,
        since TEXT,
        address TEXT,
        phone TEXT,
        zipcode TEXT,
        type TEXT,
        legal_person TEXT,
        lng DOUBLE PRECISION,
        lat DOUBLE PRECISION,
        geom GEOGRAPHY(Point, 4326)
    );

    DROP TABLE IF EXISTS health_center;
    CREATE TABLE health_center (
        id SERIAL PRIMARY KEY,
        district TEXT,
        name TEXT,
        address TEXT,
        lng DOUBLE PRECISION,
        lat DOUBLE PRECISION,
        geom GEOGRAPHY(Point, 4326)
    );
    """

    cur.execute(sql)
    conn.commit()
    cur.close()
    conn.close()
    success("è¡¨ç»“æ„åˆ›å»ºå®Œæˆã€‚")


# -------- 3. å¯¼å…¥ CSV â†’ æ•°æ®åº“ --------
def import_csv():
    info("å¼€å§‹å¯¼å…¥ CSV åˆ°æ•°æ®åº“...")

    conn = psycopg2.connect(
        host=DB_HOST, port=DB_PORT, dbname=DB_NAME,
        user=DB_USER, password=DB_PASSWORD
    )
    cur = conn.cursor()

    # å…»è€æœºæ„
    cur.execute("""
        COPY elderly_service(id, district, street, name, beds, since, address, phone, zipcode, type, legal_person)
        FROM '/data/elderly_cleaned.csv'
        CSV HEADER ENCODING 'UTF8';
    """)

    # ç¤¾åŒºå«ç”ŸæœåŠ¡ä¸­å¿ƒ
    cur.execute("""
        COPY health_center(id, district, name, address)
        FROM '/data/health_cleaned.csv'
        CSV HEADER ENCODING 'UTF8';
    """)

    conn.commit()
    cur.close()
    conn.close()
    success("CSV æ•°æ®æˆåŠŸå¯¼å…¥æ•°æ®åº“ï¼")


# -------- 4. è°ƒç”¨é«˜å¾· API â†’ ç»çº¬åº¦ --------
# ä¿®æ”¹geocodeå‡½æ•°ï¼Œæ·»åŠ å¤„ç†è¿”å›ç 30001çš„é€»è¾‘
def geocode(address):
    url = "https://restapi.amap.com/v3/geocode/geo"
    params = {"key": API_KEY, "address": address, "city": "ä¸Šæµ·"}
    retries = 0
    
    # ä¿å­˜åŸå§‹åœ°å€ï¼Œç”¨äºè®°å½•æ—¥å¿—
    original_address = address
    
    while retries < MAX_RETRIES:
        try:
            r = requests.get(url, params=params, timeout=5).json()
            
            if r["status"] == "1" and r["geocodes"]:
                lng, lat = r["geocodes"][0]["location"].split(",")
                return float(lng), float(lat)
            else:
                # è·å–é”™è¯¯ä¿¡æ¯å’Œè¿”å›ç 
                error_info = r.get('info')
                status = r.get('status')
                infocode = r.get('infocode')
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯è¿”å›ç 30001ä¸”åœ°å€ä¸­åŒ…å«"ã€"
                if infocode == "30001" and "ã€" in address:
                    # åˆ†å‰²åœ°å€å¹¶å–ç¬¬ä¸€éƒ¨åˆ†
                    first_address = address.split("ã€")[0].strip()
                    info(f"åœ°å€è§£æå¤±è´¥(30001)ï¼Œå°è¯•ä½¿ç”¨ç¬¬ä¸€ä¸ªåœ°å€éƒ¨åˆ†: {first_address}")
                    
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªåœ°å€éƒ¨åˆ†é‡æ–°è¯·æ±‚
                    params["address"] = first_address
                    r_retry = requests.get(url, params=params, timeout=5).json()
                    
                    if r_retry["status"] == "1" and r_retry["geocodes"]:
                        lng, lat = r_retry["geocodes"][0]["location"].split(",")
                        success(f"ä½¿ç”¨éƒ¨åˆ†åœ°å€æˆåŠŸè·å–åæ ‡: {first_address}")
                        return float(lng), float(lat)
                    else:
                        error(f"åˆ†å‰²åœ°å€åä»è§£æå¤±è´¥ï¼Œåœ°å€ï¼š{first_address}ï¼Œè¿”å›ä¿¡æ¯ï¼š{r_retry.get('info')}")
                else:
                    error(f"åœ°ç†ç¼–ç å¤±è´¥ï¼Œåœ°å€ï¼š{original_address}ï¼Œè¿”å›ä¿¡æ¯ï¼š{error_info}ï¼ŒçŠ¶æ€ï¼š{status}ï¼Œè¿”å›ç ï¼š{infocode}")
                
        except Exception as e:
            retries += 1
            info(f"åœ°ç†ç¼–ç è¯·æ±‚å¼‚å¸¸ï¼Œé‡è¯•({retries}/{MAX_RETRIES})ï¼Œé”™è¯¯ï¼š{str(e)}")
            time.sleep(0.5)

    error(f"å¤šæ¬¡å°è¯•ååœ°ç†ç¼–ç å¤±è´¥ï¼Œåœ°å€ï¼š{original_address}")
    return None, None


def update_coordinates(table):
    info(f"å¼€å§‹åœ°ç†ç¼–ç ï¼ˆ{table}ï¼‰...")

    conn = psycopg2.connect(
        host=DB_HOST, port=DB_PORT, dbname=DB_NAME,
        user=DB_USER, password=DB_PASSWORD
    )
    cur = conn.cursor()

    cur.execute(f"SELECT id, address FROM {table} WHERE address IS NOT NULL;")
    rows = cur.fetchall()

    for id_, addr in rows:
        lng, lat = geocode(addr)
        if lng is None:
            error(f"åœ°å€å¤±è´¥ï¼š{addr}")
            continue

        cur.execute(f"""
            UPDATE {table}
            SET lng=%s, lat=%s,
                geom = ST_SetSRID(ST_MakePoint(%s, %s), 4326)
            WHERE id=%s;
        """, (lng, lat, lng, lat, id_))

        conn.commit()

        success(f"{addr} â†’ {lng}, {lat}")
        time.sleep(0.2)

    cur.close()
    conn.close()


# åœ¨update_coordinateså‡½æ•°ä¹‹åæ·»åŠ å¯¼å‡ºå‡½æ•°
def export_geocoded_data():
    """ä»æ•°æ®åº“å¯¼å‡ºåŒ…å«ç»çº¬åº¦çš„CSVæ–‡ä»¶åˆ°æœ¬åœ°dataæ–‡ä»¶å¤¹"""
    info("å¼€å§‹å¯¼å‡ºåœ°ç†ç¼–ç æ•°æ®åˆ°æœ¬åœ°CSVæ–‡ä»¶...")
    
    conn = psycopg2.connect(
        host=DB_HOST, port=DB_PORT, dbname=DB_NAME,
        user=DB_USER, password=DB_PASSWORD
    )
    cur = conn.cursor()
    
    # å¯¼å‡ºå…»è€æœåŠ¡æœºæ„æ•°æ®
    info("å¯¼å‡ºå…»è€æœåŠ¡æœºæ„æ•°æ®...")
    cur.execute("""
        SELECT id, district, name, address, lng, lat 
        FROM elderly_service 
        ORDER BY id;
    """)
    rows = cur.fetchall()
    
    # å®šä¹‰å¯¼å‡ºæ–‡ä»¶è·¯å¾„
    elderly_export_path = r"D:\geodb\data\elderly_geocoded.csv"
    with open(elderly_export_path, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        # å†™å…¥è¡¨å¤´
        writer.writerow(['id', 'district', 'name', 'address', 'lng', 'lat'])
        # å†™å…¥æ•°æ®
        for row in rows:
            writer.writerow(row)
    success(f"å…»è€æœåŠ¡æœºæ„æ•°æ®å·²å¯¼å‡ºåˆ°: {elderly_export_path}")
    
    # å¯¼å‡ºç¤¾åŒºå«ç”ŸæœåŠ¡ä¸­å¿ƒæ•°æ®
    info("å¯¼å‡ºç¤¾åŒºå«ç”ŸæœåŠ¡ä¸­å¿ƒæ•°æ®...")
    cur.execute("""
        SELECT id, district, name, address, lng, lat 
        FROM health_center 
        ORDER BY id;
    """)
    rows = cur.fetchall()
    
    health_export_path = r"D:\geodb\data\health_geocoded.csv"
    with open(health_export_path, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        # å†™å…¥è¡¨å¤´
        writer.writerow(['id', 'district', 'name', 'address', 'lng', 'lat'])
        # å†™å…¥æ•°æ®
        for row in rows:
            writer.writerow(row)
    success(f"ç¤¾åŒºå«ç”ŸæœåŠ¡ä¸­å¿ƒæ•°æ®å·²å¯¼å‡ºåˆ°: {health_export_path}")
    
    cur.close()
    conn.close()
    success("åœ°ç†ç¼–ç æ•°æ®å¯¼å‡ºå®Œæˆï¼")

# ä¿®æ”¹ä¸»å‡½æ•°ï¼Œåœ¨åœ°ç†ç¼–ç åæ·»åŠ å¯¼å‡ºæ“ä½œ
if __name__ == "__main__":
    print("\n======= ğŸš€ ä¸€é”®å¯¼å…¥ç³»ç»Ÿå¯åŠ¨ =======\n")

    copy_csv_to_container()
    init_tables()
    import_csv()
    update_coordinates("elderly_service")
    update_coordinates("health_center")
    export_geocoded_data()  # æ·»åŠ è¿™è¡Œæ¥å¯¼å‡ºåœ°ç†ç¼–ç åçš„æ•°æ®

    print("\n======= ğŸ‰ å…¨éƒ¨å®Œæˆï¼Œå¯ä»¥ä¸Šåœ°å›¾äº†ï¼ =======")